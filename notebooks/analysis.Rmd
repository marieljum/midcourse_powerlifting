---
title: "Exploration of USAPL Powerlifting Database Using R"
output: html_notebook
---
```{r}
library(tidyverse)
library(sf)
library(leaflet)
```

**1. Using the read_csv() function, read the datasets into your notebook.**

  - Comp_types = All USAPL competitions and their urls from USAPL website.
  
  - Usapl = Webscraped results from urls of USAPL competitions.
  
  - Us_states = List of 50 US States. 
  
  - Usapl_timed_out = Webscraped results from urls with timed out errors during Python webscraping. 
  
  - Usapl_list_index = Webscraped results from urls with "list index out of range" errors during Python webscraping.
  
  - Us_states_shp = 2018 shapefile of states in US. Downloaded from US Census Bureau website (https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html). 

```{r}
comp_types <- read_csv('../data/original/USAPL_competitions_new.csv', show_col_types = FALSE)
usapl <- read_csv('../data/original/usapl_newnew.csv', show_col_types = FALSE)
usapl_timedout <- read_csv('../data/original/usapl_timed_out.csv', show_col_types = FALSE)
usapl_listindex <- read_csv('../data/original/usapl_list_index.csv', show_col_types = FALSE)
us_states <- read.delim('../data/us_states', header = TRUE)
us_states_shp <- st_read('../data/cb_2018_us_state/cb_2018_us_state_20m.shp')
```

*Notate the number of results for each webscraped results:*
```{r}
nrow(usapl)
nrow(usapl_timedout)
nrow(usapl_listindex)
```


*Merge usapl webscraped results.* 
```{r}
usapl <- rbind(usapl, usapl_timedout, usapl_listindex)
nrow(usapl)
```

*Rename columns in comp_types DF to match column names in usapl DF.* 
```{r}
comp_types <- comp_types |> 
  rename(`Meet Date` = Date, `Meet Name` = Name, `Meet Location`= State)
```

**2. Do some exploratory data analysis.** 

*There were some errors retrieving data from some urls due to request being timed out. Check if usapl DF has these competitions' data:*
```{r}
usapl |> 
  filter(`Meet Name` == "California State Games") |> 
  distinct(`Meet Date`)
```

*How many unique meets are in usapl DataFrame?* 
Some Meet Names are repeated every year so it makes sense if there's more sanction numbers than meet names. Some meets also don't have sanction numbers. Need to create a Unique Identification Number later. 
```{r}
length(unique(usapl$`Sanction Number`))
print(length(unique(usapl$`Meet Name`)))
```

*How many unique meets are in comp_types DataFrame?* 
```{r}
nrow(comp_types)
length(unique(usapl$`Sanction Number`))
length(unique(usapl$`Meet Name`))
```

**3. Compare the number of competitions listed under each meet type in USAPL results database (https://usapl.liftingdatabase.com/competitions-default?t=&s=).** 
There are nine meet types in USAPL Federation: International, IPF (International POwerlifting Federation), Local, NAPF (North American Powerlifting Federation), Pro Meet, Pro Series, Regional, and State. There are no International meets so it is not included in dataset. 

According to USAPL results database online, there should be: 
- IPF = 67
- Local = 2597
- NAPF = 4
- National = 124
- Pro Meet = 12
- Pro Series = 21
- Regional = 51
- State = 392
- Total = 3268

The total matches the number of observations in comp_types DF. 

**4. Data Cleaning/ Exploring**

*Convert Meet Date column in both DataFrames to Date type. Need to create a new column with Date type for usapl DF because some meets in Meet Date column contain a range of dates.* 
```{r}
comp_types <- comp_types |> 
  mutate(`Meet Date` = mdy(`Meet Date`))
str(comp_types$`Meet Date`)

usapl <- usapl |> 
  mutate(`Date Format` = mdy(substr(`Meet Date`, 1, 10)))
str(usapl$`Date Format`)
```

*What do the meets without Sanction Numbers look like? How many meets have no Sanction Numbers?*
```{r}
comp_types |> 
  filter(is.na(`Sanction Number`)) |> 
  nrow()
```

*How many meets without Sanction Numbers have distinct meet names or meet dates in comp_types DF?*
```{r}
comp_types |> 
  filter(is.na(`Sanction Number`)) |> 
  distinct(`Meet Name`) |> 
  nrow()

comp_types |> 
  filter(is.na(`Sanction Number`)) |> 
  distinct(`Meet Date`) |> 
  nrow()
```

**5. Create a Unique Identification column for both DataFrames. Remove duplicates.**
Format: Meet_Date - Meet_Name

*a) Create the Unique Identification column.* 
```{r}
comp_types <- comp_types |> 
  mutate(`Unique Identification` = paste(`Meet Date`, `Meet Name`, sep='-'))

usapl <- usapl |> 
  mutate(`Unique Identification` = paste(`Date Format`, `Meet Name`, sep='-'))
```

*b) Extract these datasets with ALL data and new columns:*
```{r}
# write.csv(comp_types,
#           "../data/comp_types_ALL.csv",
#           row.names=FALSE)
# 
# write.csv(usapl,
#           "../data/usapl_ALL.csv",
#           row.names=FALSE)
```

*c) Extract the names of duplicates:*
Note: Original DF has 3268 observations. How many after duplicate removal? 3258 observations. 
```{r}
duplicates <- comp_types |> 
  group_by(`Unique Identification`) |> 
  filter(n()>1) |> 
  distinct(`Unique Identification`) |> 
  pull()

duplicates
```

*d) Remove duplicates.* 
```{r}
comp_types <- comp_types |>
  filter(!(`Unique Identification` %in% duplicates))

usapl <- usapl |>
  filter(!(`Unique Identification` %in% duplicates))

nrow(comp_types)
nrow(usapl)
```


**6. Remove meet locations outside the US in usapl database. Original data contained 224,815 rows. How many rows does the new data have?**
```{r}
usapl <- usapl |> 
  filter(`Meet Location` %in% us_states$Name) 

nrow(usapl)
```

**7. Add Type info to usapl DF by merging comp_types DF with usapl DF using Unique Identification column. Remove repeating column names in comp_types DF first. **
*Export this current usapl DataFrame with all new column names.* 
```{r}
types <- comp_types |> 
  select(`Meet Type`, `Unique Identification`)

usapl <- merge(usapl, types, by="Unique Identification")

#Reorder columns
usapl |>
  select(`Meet Name`, `Meet Date`, `Meet Location`, `Sanction Number`, `Unique Identification`, `Meet Director`, `Meet Type`, everything())

# Export to csv
write.csv(usapl,
          "../notebooks/usapl_shiny/data/usapl_PROJ.csv",
          row.names=FALSE)
```


**8. Export DataFrames/ Shapefiles. Merge us_states shapefile to comp_types DF using Meet Location column (comp_types)/ Name column (us_states_shp). Convert DataFrame to a shapefile so it can be visualized in a map.**
```{r}
us_states_shp <- us_states_shp |> 
  select(STUSPS, "Meet Location" = NAME, geometry)

comp_types <- merge(comp_types, us_states_shp, by="Meet Location")

comp_types <- st_sf(comp_types)

# Make sure only the records with locations in US States are kept
comp_types <- comp_types |> 
  filter(`Meet Location` %in% us_states$Name)

# Received a warning about inconsistent datum. Needed '+proj=longlat +datum=WGS84'
comp_types <- st_transform(comp_types, crs = st_crs("+proj=longlat +datum=WGS84"))

# Export Shapefile to shp
st_write(comp_types,
          "../notebooks/usapl_shiny/data/comp_types_PROJ.shp",
         crs = st_crs(4326),
         encoding = "UTF-8",
         append = FALSE,
         row.names=FALSE)
```

**9. Plot map of all competitions by state using leaflet.**
```{r}
leaflet(comp_types) |>
          addTiles() |> 
          addPolygons(
            fillColor = "blue",
            fillOpacity = 0.5,
            color = "white",
            weight = 1,
            label = ~`Meet Location`,
            popup = ~paste(
              "Meet Name: ", `Meet Name`,
              "<br>Meet Date: ", `Meet Date`,
              "<br>Type: ", `Meet Type`
            )
          ) |> 
  setView(lng = -98.5795, lat = 39.8283, zoom = 4)
```

