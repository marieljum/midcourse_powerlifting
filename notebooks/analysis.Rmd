---
title: "Exploration of USAPL Powerlifting Database Using R"
output: html_notebook
---
```{r}
library('tidyverse')
```

**1. Using the read_csv() function, read the datasets into your notebook.**
  - Comp_types = All USAPL competitions and their urls from USAPL website.
  - Usapl = Webscraped results from urls of USAPL competitions.
  - Us_states = List of 50 US States. 

```{r}
comp_types <- read_csv('../data/USAPL_competitions.csv', show_col_types = FALSE)
usapl <- read_csv('../data/usapl_update.csv', show_col_types = FALSE)
us_states <- read.delim('../data/us_states', header = TRUE)
```

**2. Do some exploratory data analysis.** 

How many unique meets are in usapl DataFrame? 
Some Meet Names are repeated every year so it makes sense if there's more sanction numbers than meet names. Some meets also don't have sanction numbers. Need to create a Unique Identification Number later. 
```{r}
length(unique(usapl$`Sanction Number`))
print(length(unique(usapl$`Meet Name`)))
length(unique(usapl$`Meet Date`))
```

How many unique meets are in comp_types DataFrame? 
```{r}
nrow(comp_types)
```

Rename columns in comp_types DF to match column names in usapl DF. 
```{r}
comp_types <- comp_types |> 
  rename(`Meet Date` = Date, `Meet Name` = Name, `Meet Location`= State)
```

**3. Compare usapl DataFrame to comp_types DataFrame. There are 3255 meet results in comp_types, but the distinct count in usapl does not match this.**

Missing_data_usapl is the DataFrame with rows containing information from meets in usapl DF but not found in comp_types DF. 
Why didn't these meets show up in the comp_types DF? 
```{r}
missing_data_usapl <- anti_join(usapl, comp_types, by = c("Meet Name", "Sanction Number"))

length(unique(missing_data_usapl$`Meet Name`))
print(unique(missing_data_usapl$`Meet Name`))
print(length(unique(missing_data_usapl$`Sanction Number`)))
print(unique(missing_data_usapl$`Sanction Number`))
```
What do the rows for these meets look like in the usapl DF? 
```{r}
missing_data_usapl |> 
  select(1:5) |> 
  unique()
```

Test to check if these meets are in the comp_types DF:
```{r}
comp_types |> 
  filter(`Meet Name` == "South Dakota State Championships")
```
Check if these meets are in usapl DF:
```{r}
usapl |> 
  filter(`Meet Name` == "South Dakota State Championships")
```

Search for empty Sanction Numbers column:
```{r}
usapl |> 
  filter(is.na(`Sanction Number`)) |> 
  distinct(`Meet Name`)
```

It looks like something may have gone wrong with the webscraping since these meets appear to show up in the both DF's, but it has missing rows of information in the usapl DF. 

*Explore why these meets are not showing properly in the usapl DF.*
1. Re-run webscraping Python code for these meets. 
2. Remove these meets from the usapl DF and concatenate the new webscraped results to usapl DF. 

**4. Extract meets from comp_types DF with urls that work and do not work.**

Missing_data_comp is the DataFrame with rows containing information from meets listed in comp_types DF but not found in usapl DF. 
```{r}
missing_data_comp <- anti_join(comp_types, usapl, by = c("Meet Name", "Meet Date", "Sanction Number"))

length(unique(missing_data_comp$`Meet Name`))
print(length(unique(missing_data_comp$`Meet Name`)))
```

Verify that missing_data_comp DF contains meets that are not listed in usapl DF:
```{r}
usapl |> 
  filter(`Meet Name` == "World Men's Classic Championships")
```
**5. Look for meets located in the US.** 
```{r}
us_meets <- comp_types |> 
  filter(`Meet Location` %in% us_states$Name)
```

How many meets are there in the US? 
There is a total of 3255 meets scraped from the USAPL website in comp_types DF. 96 meets are located outside of the US. 
```{r}
length(unique(us_meets$`Sanction Number`)) 
```

How many meets in comp_types have no Sanction Numbers? 

```{r}
comp_types |> 
  filter(is.na(`Sanction Number`)) |> 
  nrow() 
```
```{r}
comp_types |> 
  filter(is.na(`Sanction Number`)) |>
  distinct(`Meet Date`) |> 
  nrow()
```

```{r}
comp_types |> 
  filter(`Meet Type` == "State")
```


**6. Which US meets have normal-looking URLs? Which have faulty URLs?** 

In us_meets DF, extract the meets with urls that looks normal (contains "https://usapl.liftingdatabase.com/competitions-view"). How many meets are there? Some meets do not have a sanction number.  
```{r}
us_meets_good_url <- us_meets |>
  filter(grepl("https://usapl.liftingdatabase.com/competitions-view", Website))

nrow(us_meets_good_url)
length(unique(us_meets_good_url$`Sanction Number`))
```
Find the meets in US that has faulty url's. How many meets are there?
```{r}
us_meets_faulty_url <- us_meets |>
  filter(grepl("https://usapl.liftingdatabase.com/http://", Website))

nrow(us_meets_faulty_url)
length(unique(us_meets_faulty_url$`Sanction Number`))
```

Check us_meets_good_url DataFrame if it has any of the competitions listed in usapl. Verify with three random meets listed in usapl DF. 
```{r}
us_meets_good_url |> 
  filter(`Meet Name` == "Virginia Open State Championships")
```
**7. Extract these list of URLs to a csv for another attempt at webscraping the data**

Extract from us_meets_good_url DF: 
```{r}
only_good_urls <- us_meets_good_url |> 
  select(Website)

# write.csv(only_good_urls, 
#           "../data/only_good_urls.csv", 
#          row.names=FALSE )
```

Extract from us_meets_faulty_url DF: 
```{r}
us_meets_faulty_url$Website <- gsub("https://usapl.liftingdatabase.com/", 
                                    "", 
                                    us_meets_faulty_url$Website)

us_meets_faulty_url
```

**8. Check the comp_types DF to find the meets that did not have webscraped data**
```{r}
missing_data_comp_update <- anti_join(us_meets_good_url, usapl, by = c("Meet Name", "Meet Date", "Sanction Number", "Meet Location"))

length(unique(missing_data_comp$`Meet Name`))
length(unique(missing_data_comp$`Meet Name`))
```

*Extract these url's into another csv to be webscraped.* 
```{r}
missing_data_urls <- missing_data_comp_update |>
  select(Website)

# write.csv(missing_data_urls,
#           "../data/missing_data_urls.csv",
#           row.names=FALSE)
```

**9. Import new webscraped DataFrames and merge them to combine ALL scraped data.**

*Note:* 
  - *usapl_update.csv is a merged DF of two initial usapl DF's AND missingdata.csv. usapl_update.csv is current usapl DF.* 
  - *missingdata.csv is the result of webscraping missing_data_urls.csv* 
  - *missinginfo.csv is the result of updating retrieve_info function in Python code because these meets had a table[0] (meet_info table) with less than four tags.* 

*a) Import missinginfo.csv.* 
```{r}
missinginfo <- read_csv('../data/missinginfo.csv', show_col_types = FALSE)
```

*b) To avoid duplication, remove the twenty meets that had missing info in the meet_info column types (meet info to meet director columns).* 

In missing_data_usapl DF, pull the names of each meet. 
```{r}
missing_info_names <- missing_data_usapl |> 
  distinct(`Meet Name`) |> 
  pull()

missing_info_names
```

*c) Filter the usapl DF for those meets using that list of names.* 
Test:
```{r}
usapl |> 
  filter(`Meet Name` %in% missing_info_names) |> 
  filter(is.na(`Meet Date`)) |> 
  distinct(`Meet Name`)
```
*d) Remove those meets from the usapl DF.* 
```{r}
usapl <- usapl |> 
  filter(!(`Meet Name` %in% missing_info_names & is.na(`Meet Date`)))
```

Verify that those meets are gone: 
```{r}
usapl |> 
  filter(`Meet Name` %in% missing_info_names) |> 
  filter(is.na(`Meet Date`))
```

*e) Merge missinginfo DF with usapl DF:*
```{r}
usapl_update <- unique(rbind(usapl, missinginfo))
```

Verify that those meets exist: 
```{r}
usapl_update |> 
  filter(`Meet Name` %in% missing_info_names) |> 
  select(1:4)
```

Some meets have a different format for information in table[0]. Meet Location is a website. Search for 'http' in this column. 
```{r}
usapl_update |> 
  distinct(`Meet Location`)
```
Replace these inputs with the correct value. 
```{r}
replace_location <- c('http://goodlift.info/competitions.php?year=2018',
             'Robert Wilks',
             'http://styrkeloft.no/resultatservice/?page=protokoll_vis&id=3874',
             'http://styrkeloft.no/resultatservice/?page=protokoll_vis&id=3526',
             'http://styrkeloft.no/resultatservice/?page=protokoll_vis&id=3093',
             'http://styrkeloft.no/resultatservice/?page=protokoll_vis&id=3008'
)

usapl_update |> 
  filter(`Meet Location` %in% replace_location) |> 
  mutate(`Meet Location` = "")
```

Manually correct Meet Director for Pacific Invitationals meet: 
```{r}
usapl_update |> 
  filter(`Meet Name` == 'Pacific Invitationals') |> 
  mutate(`Meet Director` = "Robert Wilks")
```

Replace values in the column and save it to the complete dataset.
```{r}
usapl_update <- usapl_update %>%
  mutate(`Meet Director` = ifelse(`Meet Name` == 'Pacific Invitationals', "Robert Wilks", `Meet Director`),
         `Meet Location` = ifelse(`Meet Location` %in% replace_location, "", `Meet Location`))
```

Verify these changes exist.
```{r}
usapl_update |> 
  filter(`Meet Name` == 'Pacific Invitationals')
```

*Create the Unique Identification column:*
Unique Identification will include 
- Meet_Type - Meet_Date - Meet_Name - Website(values after "=" sign).


First, convert Meet Date column in Comp_Types DF to Date type. 
```{r}
comp_types <- comp_types |> 
  mutate(`Meet Date` = mdy(`Meet Date`))
```

Create Unique Identification Column in Comp_Types DF:
```{r}
# comp_types <- comp_types |>
#   mutate(`Unique Identification` = paste(`Meet Type`,`Meet Date`, `Meet Name`, str_extract(Website, "\\d+"), sep='-'))

comp_types <- comp_types |>
  mutate(`Unique Identification` = paste(`Meet Type`,`Meet Date`, `Meet Name`, sep='-'))
```

*Some meets in comp_types have duplicates unique ID. Pull their unique identification names to a variable that can be used in usapl_updated DF. Then update their unique ID names by adding the ID number in Website column, which is after the "=" sign.* 

Pull their unique identification names. 
```{r}
duplicate_id_names <- comp_types |> 
  group_by(`Unique Identification`) |> 
  filter(n()>1)
```

```{r}
comp_types |> 
  group_by(`Unique Identification`) |> 
  filter(n()>1) |> 
  mutate(`Unique Identification` = paste(`Meet Type`,`Meet Date`, `Meet Name`, str_extract(Website, "\\d+"), sep='-'))
```

Update the Unique Identification column in Comp_Types DF:
```{r}
comp_types <- comp_types |>
  mutate(`Unique Identification` = ifelse(duplicated(`Unique Identification`) | duplicated(`Unique Identification`, fromLast = TRUE),
                                           paste(`Meet Type`, `Meet Date`, `Meet Name`, str_extract(Website, "\\d+"), sep = '-'),
                                           `Unique Identification`))

```

Check that there are no more duplicates:
```{r}
comp_types |> 
  group_by(`Unique Identification`) |> 
  filter(n()>1)
```

Create a new Date Format column in usapl_update DF. 
```{r}
usapl_update <- usapl_update |> 
  mutate(`Date Format` = mdy(substr(`Meet Date`, 1, 10)))
```

**Extract names of meets under their competition type:**
```{r}
type_IPF <- comp_types |> 
  filter(`Meet Type` == "IPF") |> 
  distinct(`Meet Name`) |> 
  pull()

type_Local <- comp_types |> 
  filter(`Meet Type` == "Local") |> 
  distinct(`Meet Name`) |> 
  pull()

type_NAPF <- comp_types |> 
  filter(`Meet Type` == "NAPF") |> 
  distinct(`Meet Name`) |> 
  pull()

type_National <- comp_types |> 
  filter(`Meet Type` == "National") |> 
  distinct(`Meet Name`) |> 
  pull()

type_Pro_Meet <- comp_types |> 
  filter(`Meet Type` == "Pro Meet") |> 
  distinct(`Meet Name`) |> 
  pull()

type_Pro_Series <- comp_types |> 
  filter(`Meet Type` == "Pro Series") |> 
  distinct(`Meet Name`) |> 
  pull()

type_Regional <- comp_types |> 
  filter(`Meet Type` == "Regional") |> 
  distinct(`Meet Name`) |> 
  pull()

type_State <- comp_types |> 
  filter(`Meet Type` == "State") |> 
  distinct(`Meet Name`) |> 
  pull()
```

*Create a Meet Type column in usapl_update and update it with meet type from type variables:*
```{r}
usapl_update <- usapl_update |> 
  mutate(`Meet Type` = case_when(`Meet Name` %in% type_IPF ~ 'IPF',
                                 `Meet Name` %in% type_Local ~ 'Local',
                                 `Meet Name` %in% type_NAPF ~ 'NAPF',
                                 `Meet Name` %in% type_National ~ 'National',
                                 `Meet Name` %in% type_Pro_Meet ~ 'Pro Meet',
                                 `Meet Name` %in% type_Pro_Series ~ 'Pro Series',
                                 `Meet Name` %in% type_Regional ~ 'Regional',
                                 `Meet Name` %in% type_State ~ 'State',
                                 TRUE ~ NA_character_
                                 )
         )
```

*Create a Unique Identification column in usapl_update.* 
```{r}
usapl_update <- usapl_update |>
  mutate(`Unique Identification` = paste(`Meet Type`, `Date Format`, `Meet Name`, sep='-'))
```

Check for duplicates in Unique Identification column in usapl_update DF: 
```{r}
duplicate_id_names
```
Saved duplicates in usapl_update DF into their own DF:
```{r}
duplicates_in_usapl <- usapl_update |> 
  filter(`Unique Identification` %in% duplicate_id_names$`Unique Identification`)
```

Deleted these duplicate unique ID results in usapl_update DF:
```{r}
usapl_update <- usapl_update |> 
  filter(!(`Unique Identification` %in% duplicate_id_names$`Unique Identification`))
```

**Update their names in Unique Identification column. Merge this DF back with usapl_update DF.**
```{r}
duplicates_in_usapl |> 
  filter(`Unique Identification` == "Local-2018-03-18-Chicagoland Men's Raw Open") |> distinct(`Meet Name`)
```
```{r}
duplicates_in_usapl |>
  mutate(`Unique Identification` = case_when(
    `Unique Identification` == "Local-2020-09-19-Thunder Open" & `Sanction Number` == "CO-2020-05" ~ "Local-2020-09-19-Thunder Open-119468",
    `Unique Identification` == "Local-2020-09-19-Thunder Open" & `Sanction Number` == "CO-2020-07" ~ "Local-2020-09-19-Thunder Open-119479",
    TRUE ~ `Unique Identification`
  ))
```


Check how many unique meets are in this DF. There are 2966 meets in the US. I might have meets that do not have unique identification numbers, such as sanction numbers but are still located in the US. 
```{r}
length(unique(usapl$`Sanction Number`))
length(unique(usapl$`Meet Name`))
```

