---
title: "Exploration of USAPL Powerlifting Database Using R"
output: html_notebook
---
```{r}
library('tidyverse')
```

**1. Using the read_csv() function, read the datasets into your notebook.**

  - Comp_types = All USAPL competitions and their urls from USAPL website.
  
  - Usapl = Webscraped results from urls of USAPL competitions.
  
  - Us_states = List of 50 US States. 
  
  - Usapl_timed_out = Webscraped results from urls with timed out errors during Python webscraping. 
  
  - Usapl_list_index = Webscraped results from urls with "list index out of range" errors during Python webscraping.

```{r}
comp_types <- read_csv('../data/USAPL_competitions_new.csv', show_col_types = FALSE)
usapl <- read_csv('../data/usapl_newnew.csv', show_col_types = FALSE)
usapl_timedout <- read_csv('../data/usapl_timed_out.csv', show_col_types = FALSE)
usapl_listindex <- read_csv('../data/usapl_list_index.csv', show_col_types = FALSE)
us_states <- read.delim('../data/us_states', header = TRUE)
```

*Notate the number of results for each webscraped results:*
```{r}
nrow(usapl)
nrow(usapl_timedout)
nrow(usapl_listindex)
```


*Merge usapl webscraped results.* 
```{r}
usapl <- rbind(usapl, usapl_timedout, usapl_listindex)
nrow(usapl)
```

*Rename columns in comp_types DF to match column names in usapl DF.* 
```{r}
comp_types <- comp_types |> 
  rename(`Meet Date` = Date, `Meet Name` = Name, `Meet Location`= State)
```

**2. Do some exploratory data analysis.** 

*There were some errors retrieving data from some urls due to request being timed out. Check if usapl DF has these competitions' data:*
```{r}
usapl |> 
  filter(`Meet Name` == "California State Games") |> 
  distinct(`Meet Date`)
```

*How many unique meets are in usapl DataFrame?* 
Some Meet Names are repeated every year so it makes sense if there's more sanction numbers than meet names. Some meets also don't have sanction numbers. Need to create a Unique Identification Number later. 
```{r}
length(unique(usapl$`Sanction Number`))
print(length(unique(usapl$`Meet Name`)))
```

*How many unique meets are in comp_types DataFrame?* 
```{r}
nrow(comp_types)
length(unique(usapl$`Sanction Number`))
length(unique(usapl$`Meet Name`))
```

**3. Compare the number of competitions listed under each meet type in USAPL results database (https://usapl.liftingdatabase.com/competitions-default?t=&s=).** 
There are nine meet types in USAPL Federation: International, IPF (International POwerlifting Federation), Local, NAPF (North American Powerlifting Federation), Pro Meet, Pro Series, Regional, and State. There are no International meets so it is not included in dataset. 

According to USAPL results database online, there should be: 
- IPF = 67
- Local = 2597
- NAPF = 4
- National = 124
- Pro Meet = 12
- Pro Series = 21
- Regional = 51
- State = 392
- Total = 3268

The total matches the number of observations in comp_types DF. 

**4. Data Cleaning/ Exploring**

*Convert Meet Date column in both DataFrames to Date type. Need to create a new column with Date type for usapl DF because some meets in Meet Date column contain a range of dates.* 
```{r}
comp_types <- comp_types |> 
  mutate(`Meet Date` = mdy(`Meet Date`))
str(comp_types$`Meet Date`)

usapl <- usapl |> 
  mutate(`Date Format` = mdy(substr(`Meet Date`, 1, 10)))
str(usapl$`Date Format`)
```

*What do the meets without Sanction Numbers look like? How many meets have no Sanction Numbers?*
```{r}
comp_types |> 
  filter(is.na(`Sanction Number`)) |> 
  nrow()
```

*How many meets without Sanction Numbers have distinct meet names or meet dates in comp_types DF?*
```{r}
comp_types |> 
  filter(is.na(`Sanction Number`)) |> 
  distinct(`Meet Name`) |> 
  nrow()

comp_types |> 
  filter(is.na(`Sanction Number`)) |> 
  distinct(`Meet Date`) |> 
  nrow()
```

**5. Create a Unique Identification column for both DataFrames. Remove duplicates and export DataFrame as csv.**
Format: Meet_Date - Meet_Name

*a) Create the Unique Identification column.* 
```{r}
comp_types <- comp_types |> 
  mutate(`Unique Identification` = paste(`Meet Date`, `Meet Name`, sep='-'))

usapl <- usapl |> 
  mutate(`Unique Identification` = paste(`Date Format`, `Meet Name`, sep='-'))
```

*b) Extract these datasets with ALL data and new columns:*
```{r}
write.csv(comp_types,
          "../data/comp_types_ALL.csv",
          row.names=FALSE)

write.csv(usapl,
          "../data/usapl_ALL.csv",
          row.names=FALSE)
```

*c) Extract the names of duplicates:*
Note: Original DF has 3268 observations. How many after duplicate removal? 3258 observations. 
```{r}
duplicates <- comp_types |> 
  group_by(`Unique Identification`) |> 
  filter(n()>1) |> 
  distinct(`Unique Identification`) |> 
  pull()

duplicates
```

*d) Remove duplicates.* 
```{r}
comp_types <- comp_types |>
  filter(!(`Unique Identification` %in% duplicates))

usapl <- usapl |>
  filter(!(`Unique Identification` %in% duplicates))

nrow(comp_types)
nrow(usapl)
```

*e) Export these DataFrames as csv's, which will be used for project.*
```{r}
write.csv(comp_types,
          "../data/comp_types_PROJ.csv",
          row.names=FALSE)

write.csv(usapl,
          "../data/usapl_PROJ.csv",
          row.names=FALSE)
```

