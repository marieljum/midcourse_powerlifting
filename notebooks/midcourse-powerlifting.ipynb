{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a3b6d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdddb593",
   "metadata": {},
   "source": [
    "**1. Navigate to https://usapl.liftingdatabase.com/competitions. Using BeautifulSoup, extract information from each competition's website.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca406dd2",
   "metadata": {},
   "source": [
    "General notes from the competitions' default database:\n",
    "\n",
    "- \"All\" for Type and State has the following HTML: https://usapl.liftingdatabase.com/competitions-default?t=&s=. \n",
    "- Changing the Type but keeping State as \"All\" changes the number after 't ='\n",
    "- T =  \n",
    "    - International = 10 \n",
    "    - IPF = 5\n",
    "    - Local = 3\n",
    "    - NAPF = 7\n",
    "    - National = 2\n",
    "    - Pro Meet = 9 \n",
    "    - Pro Series = 8\n",
    "    - Regional = 4\n",
    "    - State = 6\n",
    "- Changing the State but keeping Type as \"All\":\n",
    "    - Alabama: default?t=&s=1\n",
    "    - Tennessee: default?t=&s=42\n",
    "    - Wyoming: default?t=&s=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a844a7d",
   "metadata": {},
   "source": [
    "**Code to retrieve results from a competition's url:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe7e443",
   "metadata": {},
   "source": [
    "def extract_category(td_tag):\n",
    "    th_tag_before = td_tag.find_previous('th')  # Find the previous th tag\n",
    "    th_tag_after = td_tag.find_next('th')  # Find the next th tag\n",
    "\n",
    "    if th_tag_before and th_tag_after:\n",
    "        # If the td tag is between two th tags, retrieve the previous th element\n",
    "        return th_tag_before.get_text().strip()\n",
    "    elif th_tag_before:\n",
    "        # If the td tag is after a th tag, retrieve the previous th element\n",
    "        return th_tag_before.get_text().strip()\n",
    "    elif th_tag_after:\n",
    "        # If the td tag is before a th tag, retrieve the next th element\n",
    "        return th_tag_after.get_text().strip()\n",
    "    else:\n",
    "        return None    \n",
    "url = 'https://usapl.liftingdatabase.com/competitions-view?id=120904'\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text)    \n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Main html element where data is located \n",
    "    content = soup.find('div', id=\"content\")\n",
    "\n",
    "    if content:\n",
    "        tables = content.findAll('table')\n",
    "\n",
    "        if tables: \n",
    "            meet_info = tables[0]\n",
    "            meet_results = tables[1]\n",
    "\n",
    "            # This is the table with competitor results\n",
    "            if meet_results:\n",
    "                tr_tags = meet_results.findAll('tr')\n",
    "\n",
    "                for tr_tag in tr_tags:\n",
    "                    td_tags = tr_tag.findAll('td')\n",
    "\n",
    "                    if len(td_tags) >= 2:\n",
    "                        category = extract_category(td_tags[0])\n",
    "                        weight_class = td_tags[0].get_text().strip().replace('-', '')\n",
    "                        placement = td_tags[1].get_text().strip().replace('.', '')\n",
    "                        name = td_tags[2].get_text().strip()\n",
    "                        yob = td_tags[3].get_text().strip()\n",
    "                        team = td_tags[4].get_text().strip()\n",
    "                        state = td_tags[5].get_text().strip()\n",
    "                        lot = td_tags[6].get_text().strip()\n",
    "                        weight = td_tags[7].get_text().strip()\n",
    "                        squat_1 = td_tags[8].get_text().strip()\n",
    "                        squat_2 = td_tags[9].get_text().strip()\n",
    "                        squat_3 = td_tags[10].get_text().strip()\n",
    "                        bench_1 = td_tags[11].get_text().strip()\n",
    "                        bench_2 = td_tags[12].get_text().strip()\n",
    "                        bench_3 = td_tags[13].get_text().strip()\n",
    "                        deadlift_1 = td_tags[14].get_text().strip()\n",
    "                        deadlift_2 = td_tags[15].get_text().strip()\n",
    "                        deadlift_3 = td_tags[16].get_text().strip()\n",
    "                        total = td_tags[17].get_text().strip()\n",
    "                        points = td_tags[18].get_text().strip()\n",
    "                        drug_tested = td_tags[19].get_text().strip()\n",
    "\n",
    "                        # Find the previous th tag for the event\n",
    "                        event = tr_tag.find_previous('th', 'competition_view_event').get_text().strip()\n",
    "                        \n",
    "                        # Create a dictionary for each row\n",
    "                        meet_results_data = {\n",
    "                            'Event': event,\n",
    "                            'Category': category,\n",
    "                            'Weight Class': weight_class,\n",
    "                            'Placement': placement,\n",
    "                            'Name': name,\n",
    "                            'Year of Birth': yob,\n",
    "                            'Team': team,\n",
    "                            'State': state,\n",
    "                            'Lot': lot,\n",
    "                            'Weight': weight,\n",
    "                            'Squat 1': squat_1,\n",
    "                            'Squat 2': squat_2,\n",
    "                            'Squat 3': squat_3,\n",
    "                            'Bench Press 1': bench_1,\n",
    "                            'Bench Press 2': bench_2,\n",
    "                            'Bench Press 3': bench_3,\n",
    "                            'Deadlift 1': deadlift_1,\n",
    "                            'Deadlift 2': deadlift_2,\n",
    "                            'Deadlift 3': deadlift_3,\n",
    "                            'Total': total,\n",
    "                            'Points': points,\n",
    "                            'Drug-Tested': drug_tested\n",
    "                        }\n",
    "\n",
    "                        # Append the dictionary to the results list\n",
    "                        results.append(meet_results_data)\n",
    "                \n",
    "                # Create a DataFrame from the results list\n",
    "                meet_results_df = pd.DataFrame(results)\n",
    "\n",
    "            # This is table with meet information\n",
    "            if meet_info:\n",
    "                tr_tags = meet_info.findAll('tr')\n",
    "\n",
    "                # Extracting date, state, and meet director information from tr_tags list\n",
    "                if len(tr_tags) >= 4:\n",
    "                    date = tr_tags[0].find('td').get_text(strip=True)\n",
    "                    sanction_num = tr_tags[1].find('td').get_text(strip=True)\n",
    "                    state = tr_tags[2].find('td').get_text(strip=True)\n",
    "                    meet_director = tr_tags[3].find('td').get_text(strip=True)\n",
    "\n",
    "                else: \n",
    "                    date = sanction_num = state = meet_director = None\n",
    "\n",
    "                # Repeat the values for each row in meet_results_df \n",
    "                meet_info_df = pd.DataFrame({\n",
    "                    'Meet Date': [date] * len(results),\n",
    "                    'Sanction Number': [sanction_num] * len(results),\n",
    "                    'Meet Location': [state] * len(results),\n",
    "                    'Meet Director': [meet_director] * len(results)                \n",
    "                })\n",
    "\n",
    "                # Concatenate the dataframes along the columns \n",
    "                results_df = pd.concat([meet_info_df, meet_results_df], axis=1)\n",
    "\n",
    "            # Retrieve meet name from h3 heading\n",
    "            # Create a new column to add to results_df\n",
    "            meet_name = content.find('h3').get_text(strip=True)\n",
    "            meet_name_df = pd.DataFrame({\n",
    "                'Meet Name': [meet_name] * len(results)\n",
    "            })\n",
    "\n",
    "            # Concatenate the dataframes along the columns \n",
    "            results_df = pd.concat([results_df, meet_name_df], axis = 1)                        \n",
    "\n",
    "            #Reorder columns in the DataFrame \n",
    "            column_order = [\n",
    "                'Meet Date', 'Meet Location', 'Meet Name', 'Meet Director', \n",
    "                'Event', 'Category', 'Weight Class', 'Placement', 'Name', \n",
    "                'Year of Birth', 'Team', 'State', 'Lot', 'Weight', \n",
    "                'Squat 1', 'Squat 2', 'Squat 3', 'Bench Press 1', \n",
    "                'Bench Press 2', 'Bench Press 3', 'Deadlift 1', \n",
    "                'Deadlift 2', 'Deadlift 3', 'Total', 'Points', 'Drug-Tested'\n",
    "            ]\n",
    "            results_df = results_df[column_order]\n",
    "\n",
    "            print('Success!')\n",
    "                \n",
    "results_df.head(2)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4eebeafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_category(td_tag):\n",
    "    th_tag_before = td_tag.find_previous('th')  # Find the previous th tag\n",
    "    th_tag_after = td_tag.find_next('th')  # Find the next th tag\n",
    "\n",
    "    if th_tag_before and th_tag_after:\n",
    "        # If the td tag is between two th tags, retrieve the previous th element\n",
    "        return th_tag_before.get_text().strip()\n",
    "    elif th_tag_before:\n",
    "        # If the td tag is after a th tag, retrieve the previous th element\n",
    "        return th_tag_before.get_text().strip()\n",
    "    elif th_tag_after:\n",
    "        # If the td tag is before a th tag, retrieve the next th element\n",
    "        return th_tag_after.get_text().strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def retrieve_info(url):\n",
    "    \"\"\"\n",
    "    This function creates a dataframe from the USAPL database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text)    \n",
    "\n",
    "            results = []\n",
    "\n",
    "            # Main html element where data is located \n",
    "            content = soup.find('div', id=\"content\")\n",
    "\n",
    "            if content:\n",
    "                tables = content.findAll('table')\n",
    "\n",
    "                if tables: \n",
    "                    meet_info = tables[0]\n",
    "                    meet_results = tables[1]\n",
    "\n",
    "                    # This is the table with competitor results\n",
    "                    if meet_results:\n",
    "                        tr_tags = meet_results.findAll('tr')\n",
    "\n",
    "                        for tr_tag in tr_tags:\n",
    "                            td_tags = tr_tag.findAll('td')\n",
    "\n",
    "                            if len(td_tags) >= 2:\n",
    "                                category = extract_category(td_tags[0])\n",
    "                                weight_class = td_tags[0].get_text().strip().replace('-', '')\n",
    "                                placement = td_tags[1].get_text().strip().replace('.', '')\n",
    "                                name = td_tags[2].get_text().strip()\n",
    "                                yob = td_tags[3].get_text().strip()\n",
    "                                team = td_tags[4].get_text().strip()\n",
    "                                state = td_tags[5].get_text().strip()\n",
    "                                lot = td_tags[6].get_text().strip()\n",
    "                                weight = td_tags[7].get_text().strip()\n",
    "                                squat_1 = td_tags[8].get_text().strip()\n",
    "                                squat_2 = td_tags[9].get_text().strip()\n",
    "                                squat_3 = td_tags[10].get_text().strip()\n",
    "                                bench_1 = td_tags[11].get_text().strip()\n",
    "                                bench_2 = td_tags[12].get_text().strip()\n",
    "                                bench_3 = td_tags[13].get_text().strip()\n",
    "                                deadlift_1 = td_tags[14].get_text().strip()\n",
    "                                deadlift_2 = td_tags[15].get_text().strip()\n",
    "                                deadlift_3 = td_tags[16].get_text().strip()\n",
    "                                total = td_tags[17].get_text().strip()\n",
    "                                points = td_tags[18].get_text().strip()\n",
    "                                drug_tested = td_tags[19].get_text().strip()\n",
    "\n",
    "                                # Find the previous th tag for the event\n",
    "                                event = tr_tag.find_previous('th', 'competition_view_event').get_text().strip()\n",
    "\n",
    "                                # Create a dictionary for each row\n",
    "                                meet_results_data = {\n",
    "                                    'Event': event,\n",
    "                                    'Category': category,\n",
    "                                    'Weight Class': weight_class,\n",
    "                                    'Placement': placement,\n",
    "                                    'Name': name,\n",
    "                                    'Year of Birth': yob,\n",
    "                                    'Team': team,\n",
    "                                    'State': state,\n",
    "                                    'Lot': lot,\n",
    "                                    'Weight': weight,\n",
    "                                    'Squat 1': squat_1,\n",
    "                                    'Squat 2': squat_2,\n",
    "                                    'Squat 3': squat_3,\n",
    "                                    'Bench Press 1': bench_1,\n",
    "                                    'Bench Press 2': bench_2,\n",
    "                                    'Bench Press 3': bench_3,\n",
    "                                    'Deadlift 1': deadlift_1,\n",
    "                                    'Deadlift 2': deadlift_2,\n",
    "                                    'Deadlift 3': deadlift_3,\n",
    "                                    'Total': total,\n",
    "                                    'Points': points,\n",
    "                                    'Drug-Tested': drug_tested\n",
    "                                }\n",
    "\n",
    "                                # Append the dictionary to the results list\n",
    "                                results.append(meet_results_data)\n",
    "\n",
    "                        # Create a DataFrame from the results list\n",
    "                        meet_results_df = pd.DataFrame(results)\n",
    "\n",
    "                    # This is table with meet information\n",
    "                    if meet_info:\n",
    "                        tr_tags = meet_info.findAll('tr')\n",
    "\n",
    "                        # Extracting date, state, and meet director information from tr_tags list\n",
    "                        if len(tr_tags) >= 4:\n",
    "                            date = tr_tags[0].find('td').get_text(strip=True)\n",
    "                            sanction_num = tr_tags[1].find('td').get_text(strip=True)\n",
    "                            state = tr_tags[2].find('td').get_text(strip=True)\n",
    "                            meet_director = tr_tags[3].find('td').get_text(strip=True)\n",
    "\n",
    "                        else: \n",
    "                            date = sanction_num = state = meet_director = None\n",
    "\n",
    "                        # Repeat the values for each row in meet_results_df \n",
    "                        meet_info_df = pd.DataFrame({\n",
    "                            'Meet Date': [date] * len(results),\n",
    "                            'Sanction Number': [sanction_num] * len(results),\n",
    "                            'Meet Location': [state] * len(results),\n",
    "                            'Meet Director': [meet_director] * len(results)\n",
    "                        }, index=results_df.index)\n",
    "\n",
    "                        # Concatenate the dataframes along the columns \n",
    "                        results_df = pd.concat([meet_info_df, meet_results_df], axis=1)\n",
    "\n",
    "                    # Retrieve meet name from h3 heading\n",
    "                    # Create a new column to add to results_df\n",
    "                    meet_name = content.find('h3').get_text(strip=True)\n",
    "                    meet_name_df = pd.DataFrame({\n",
    "                        'Meet Name': [meet_name] * len(results)\n",
    "                    })\n",
    "\n",
    "                    # Concatenate the dataframes along the columns \n",
    "                    results_df = pd.concat([results_df, meet_name_df], axis = 1)                        \n",
    "\n",
    "                    #Reorder columns in the DataFrame \n",
    "                    column_order = [\n",
    "                        'Meet Date', 'Meet Location', 'Meet Name', 'Meet Director', \n",
    "                        'Event', 'Category', 'Weight Class', 'Placement', 'Name', \n",
    "                        'Year of Birth', 'Team', 'State', 'Lot', 'Weight', \n",
    "                        'Squat 1', 'Squat 2', 'Squat 3', 'Bench Press 1', \n",
    "                        'Bench Press 2', 'Bench Press 3', 'Deadlift 1', \n",
    "                        'Deadlift 2', 'Deadlift 3', 'Total', 'Points', 'Drug-Tested'\n",
    "                    ]\n",
    "                    results_df = results_df[column_order]\n",
    "                    \n",
    "                    print('Success!')\n",
    "                    return results_df\n",
    "\n",
    "            else: \n",
    "                print(f'Error retrieving table element from {url}')\n",
    "        else: \n",
    "            print(f'Error retrieving {url}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error retrieving data from {url}: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058d002e",
   "metadata": {},
   "source": [
    "**Create DataFrame of all competition names and types in USAPL Database.** \n",
    "\n",
    "This DataFrame contains information of where and when the competition occurred along with the url that stores the results of the competition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0e2f42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame created from list of USAPL competitions.\n",
      "DataFrame saved as csv file in data folder.\n"
     ]
    }
   ],
   "source": [
    "list_of_urls = [\n",
    "    'https://usapl.liftingdatabase.com/competitions-default?t=5&s=',\n",
    "    'https://usapl.liftingdatabase.com/competitions-default?t=3&s=',\n",
    "    'https://usapl.liftingdatabase.com/competitions-default?t=7&s=',\n",
    "    'https://usapl.liftingdatabase.com/competitions-default?t=2&s=',\n",
    "    'https://usapl.liftingdatabase.com/competitions-default?t=9&s=',\n",
    "    'https://usapl.liftingdatabase.com/competitions-default?t=8&s=',\n",
    "    'https://usapl.liftingdatabase.com/competitions-default?t=4&s=',\n",
    "    'https://usapl.liftingdatabase.com/competitions-default?t=6&s='\n",
    "]\n",
    "\n",
    "competition_types = ['IPF', 'Local', 'NAPF', 'National', \n",
    "                     'Pro Meet', 'Pro Series', 'Regional', 'State']\n",
    "\n",
    "all_competitions = []\n",
    "\n",
    "# Go through list of URL and collect data\n",
    "for url, competition_type in zip(list_of_urls, competition_types):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # List to collect information from each competition \n",
    "        competition_info = []\n",
    "        \n",
    "        # Retrieve general information from list of competitions\n",
    "        tabledata = soup.find('table', 'tabledata')\n",
    "        if tabledata:\n",
    "            tr_tags = tabledata.findAll('tr')\n",
    "            \n",
    "            for tr_tag in tr_tags:\n",
    "                td_tags = tr_tag.findAll('td')\n",
    "\n",
    "                if td_tags:\n",
    "                    date = td_tags[0].get_text().strip()\n",
    "                    name = td_tags[1].get_text().strip()\n",
    "                    sanction_num = td_tags[2].get_text().strip()\n",
    "                    state = td_tags[3].get_text().strip()\n",
    "                    \n",
    "                    # Create a dictionary for each row\n",
    "                    meet_type_data = {\n",
    "                        'Date': date,\n",
    "                        'Name': name,\n",
    "                        'Meet Type': competition_type,\n",
    "                        'Sanction Number': sanction_num,\n",
    "                        'State': state\n",
    "                    }\n",
    "                    \n",
    "                    # Append dictionary to results list\n",
    "                    competition_info.append(meet_type_data)\n",
    "                    \n",
    "        else:\n",
    "            print(f'Error retrieving URL: {url}')\n",
    "            \n",
    "        # Retrieve URL information\n",
    "        anchor_tags = tabledata.findAll('a')\n",
    "        url_list = ['https://usapl.liftingdatabase.com/' + anchor_tag.get('href') for anchor_tag in anchor_tags]\n",
    "\n",
    "        # Update competition_info with Website info\n",
    "        for url, meet_type_data in enumerate(competition_info):\n",
    "            meet_type_data['Website'] = url_list[url]\n",
    "\n",
    "        # Append competition_info to overall list \n",
    "        all_competitions.extend(competition_info)\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "competition_type_df = pd.DataFrame(all_competitions)\n",
    "print('DataFrame created from list of USAPL competitions.')\n",
    "\n",
    "# Display and save DataFrame as csv\n",
    "competition_type_df\n",
    "\n",
    "competition_type_df.to_csv('../data/USAPL_competitions.csv', index = False)\n",
    "print('DataFrame saved as csv file in data folder.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830b4c6e",
   "metadata": {},
   "source": [
    "**Using list of url's from the previous code, retrieve results from each competition using retrieve_info function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28fb3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "# Iterate through each complete URL\n",
    "for url in url_list:\n",
    "    df = retrieve_info(url)\n",
    "    dfs.append(df)\n",
    "    time.sleep(1)\n",
    "    \n",
    "# Concatenate all DataFrames into one\n",
    "USAPL_powerlifting_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "USAPL_powerlifting_df.to_csv('../data/example.csv', index = False)\n",
    "print('DataFrame saved as csv file in data folder.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931b64d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
