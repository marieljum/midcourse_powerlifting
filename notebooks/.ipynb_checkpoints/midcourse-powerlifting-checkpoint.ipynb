{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a3b6d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdddb593",
   "metadata": {},
   "source": [
    "**1. Navigate to https://usapl.liftingdatabase.com/competitions. Using BeautifulSoup, extract information from each competition's website.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca406dd2",
   "metadata": {},
   "source": [
    "General notes from the competitions' default database:\n",
    "\n",
    "- \"All\" for Type and State has the following HTML: https://usapl.liftingdatabase.com/competitions-default?t=&s=. \n",
    "- Changing the Type but keeping State as \"All\" changes the number after 't ='\n",
    "    - T =  \n",
    "        - International = 10 \n",
    "        - IPF = 5\n",
    "        - Local = 3\n",
    "        - NAPF = 7\n",
    "        - National = 2\n",
    "        - Pro Meet = 9 \n",
    "        - Pro Series = 8\n",
    "        - Regional = 4\n",
    "        - State = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a844a7d",
   "metadata": {},
   "source": [
    "**Code to retrieve results from a competition's url:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eebeafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_category(td_tag):\n",
    "    th_tag_before = td_tag.find_previous('th')  # Find the previous th tag\n",
    "    th_tag_after = td_tag.find_next('th')  # Find the next th tag\n",
    "\n",
    "    if th_tag_before and th_tag_after:\n",
    "        # If the td tag is between two th tags, retrieve the previous th element\n",
    "        return th_tag_before.get_text().strip()\n",
    "    elif th_tag_before:\n",
    "        # If the td tag is after a th tag, retrieve the previous th element\n",
    "        return th_tag_before.get_text().strip()\n",
    "    elif th_tag_after:\n",
    "        # If the td tag is before a th tag, retrieve the next th element\n",
    "        return th_tag_after.get_text().strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def retrieve_info(url):\n",
    "    \"\"\"\n",
    "    This function creates a dataframe from the USAPL database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text)    \n",
    "\n",
    "            results = []\n",
    "\n",
    "            # Main html element where data is located \n",
    "            content = soup.find('div', id=\"content\")\n",
    "\n",
    "            if content:\n",
    "                tables = content.findAll('table')\n",
    "\n",
    "                if tables: \n",
    "                    meet_info = tables[0]\n",
    "                    meet_results = tables[1]\n",
    "\n",
    "                    # This is the table with competitor results\n",
    "                    if meet_results:\n",
    "                        tr_tags = meet_results.findAll('tr')\n",
    "\n",
    "                        for tr_tag in tr_tags:\n",
    "                            td_tags = tr_tag.findAll('td')\n",
    "\n",
    "                            if len(td_tags) >= 2:\n",
    "                                category = extract_category(td_tags[0])\n",
    "                                weight_class = td_tags[0].get_text().strip().replace('-', '')\n",
    "                                placement = td_tags[1].get_text().strip().replace('.', '')\n",
    "                                name = td_tags[2].get_text().strip()\n",
    "                                yob = td_tags[3].get_text().strip()\n",
    "                                team = td_tags[4].get_text().strip()\n",
    "                                state = td_tags[5].get_text().strip()\n",
    "                                lot = td_tags[6].get_text().strip()\n",
    "                                weight = td_tags[7].get_text().strip()\n",
    "                                squat_1 = td_tags[8].get_text().strip()\n",
    "                                squat_2 = td_tags[9].get_text().strip()\n",
    "                                squat_3 = td_tags[10].get_text().strip()\n",
    "                                bench_1 = td_tags[11].get_text().strip()\n",
    "                                bench_2 = td_tags[12].get_text().strip()\n",
    "                                bench_3 = td_tags[13].get_text().strip()\n",
    "                                deadlift_1 = td_tags[14].get_text().strip()\n",
    "                                deadlift_2 = td_tags[15].get_text().strip()\n",
    "                                deadlift_3 = td_tags[16].get_text().strip()\n",
    "                                total = td_tags[17].get_text().strip()\n",
    "                                points = td_tags[18].get_text().strip()\n",
    "                                drug_tested = td_tags[19].get_text().strip()\n",
    "\n",
    "                                # Find the previous th tag for the event\n",
    "                                event_tag = tr_tag.find_previous('th', 'competition_view_event')\n",
    "\n",
    "                                if event_tag: \n",
    "                                    event = event_tag.get_text().strip()\n",
    "\n",
    "                                else: \n",
    "                                    event = None\n",
    "\n",
    "                                # Create a dictionary for each row\n",
    "                                meet_results_data = {\n",
    "                                    'Event': event,\n",
    "                                    'Category': category,\n",
    "                                    'Weight Class': weight_class,\n",
    "                                    'Placement': placement,\n",
    "                                    'Name': name,\n",
    "                                    'Year of Birth': yob,\n",
    "                                    'Team': team,\n",
    "                                    'State': state,\n",
    "                                    'Lot': lot,\n",
    "                                    'Weight': weight,\n",
    "                                    'Squat 1': squat_1,\n",
    "                                    'Squat 2': squat_2,\n",
    "                                    'Squat 3': squat_3,\n",
    "                                    'Bench Press 1': bench_1,\n",
    "                                    'Bench Press 2': bench_2,\n",
    "                                    'Bench Press 3': bench_3,\n",
    "                                    'Deadlift 1': deadlift_1,\n",
    "                                    'Deadlift 2': deadlift_2,\n",
    "                                    'Deadlift 3': deadlift_3,\n",
    "                                    'Total': total,\n",
    "                                    'Points': points,\n",
    "                                    'Drug-Tested': drug_tested\n",
    "                                }\n",
    "\n",
    "                                # Append the dictionary to the results list\n",
    "                                results.append(meet_results_data)\n",
    "\n",
    "                        # Create a DataFrame from the results list\n",
    "                        meet_results_df = pd.DataFrame(results)\n",
    "\n",
    "                    # This is table with meet information\n",
    "                    if meet_info:\n",
    "                        tr_tags = meet_info.findAll('tr')\n",
    "\n",
    "                        # Extracting date, state, and meet director information from tr_tags list\n",
    "                        if len(tr_tags) >= 4:\n",
    "                            date = tr_tags[0].find('td').get_text(strip=True)\n",
    "                            sanction_num = tr_tags[1].find('td').get_text(strip=True)\n",
    "                            state = tr_tags[2].find('td').get_text(strip=True)\n",
    "                            meet_director = tr_tags[3].find('td').get_text(strip=True)\n",
    "\n",
    "                        else: \n",
    "                            date = sanction_num = state = meet_director = None\n",
    "\n",
    "                        # Repeat the values for each row in meet_results_df \n",
    "                        meet_info_df = pd.DataFrame({\n",
    "                            'Meet Date': [date] * len(results),\n",
    "                            'Sanction Number': [sanction_num] * len(results),\n",
    "                            'Meet Location': [state] * len(results),\n",
    "                            'Meet Director': [meet_director] * len(results)\n",
    "                        }, index= meet_results_df.index)\n",
    "\n",
    "                        # Concatenate the dataframes along the columns \n",
    "                        results_df = pd.concat([meet_info_df, meet_results_df], axis=1)\n",
    "\n",
    "                    # Retrieve meet name from h3 heading\n",
    "                    # Create a new column to add to results_df\n",
    "                    meet_name = content.find('h3').get_text(strip=True)\n",
    "                    meet_name_df = pd.DataFrame({\n",
    "                        'Meet Name': [meet_name] * len(results)\n",
    "                    })\n",
    "\n",
    "                    # Concatenate the dataframes along the columns \n",
    "                    results_df = pd.concat([results_df, meet_name_df], axis = 1)                        \n",
    "\n",
    "                    #Reorder columns in the DataFrame \n",
    "                    column_order = [\n",
    "                        'Meet Date', 'Sanction Number', 'Meet Location', 'Meet Name', 'Meet Director', \n",
    "                        'Event', 'Category', 'Weight Class', 'Placement', 'Name', \n",
    "                        'Year of Birth', 'Team', 'State', 'Lot', 'Weight', \n",
    "                        'Squat 1', 'Squat 2', 'Squat 3', 'Bench Press 1', \n",
    "                        'Bench Press 2', 'Bench Press 3', 'Deadlift 1', \n",
    "                        'Deadlift 2', 'Deadlift 3', 'Total', 'Points', 'Drug-Tested'\n",
    "                    ]\n",
    "                    results_df = results_df[column_order]\n",
    "                    \n",
    "                    print('Success!')\n",
    "                    return results_df\n",
    "\n",
    "            else: \n",
    "                print(f'Error retrieving table element from {url}')\n",
    "        else: \n",
    "            print(f'Error retrieving {url}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error retrieving data from {url}: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286da97a",
   "metadata": {},
   "source": [
    "**Practice run with definition functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f89ded61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Meet Date</th>\n",
       "      <th>Sanction Number</th>\n",
       "      <th>Meet Location</th>\n",
       "      <th>Meet Name</th>\n",
       "      <th>Meet Director</th>\n",
       "      <th>Event</th>\n",
       "      <th>Category</th>\n",
       "      <th>Weight Class</th>\n",
       "      <th>Placement</th>\n",
       "      <th>Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Squat 3</th>\n",
       "      <th>Bench Press 1</th>\n",
       "      <th>Bench Press 2</th>\n",
       "      <th>Bench Press 3</th>\n",
       "      <th>Deadlift 1</th>\n",
       "      <th>Deadlift 2</th>\n",
       "      <th>Deadlift 3</th>\n",
       "      <th>Total</th>\n",
       "      <th>Points</th>\n",
       "      <th>Drug-Tested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09/23/2021 - 10/03/2021</td>\n",
       "      <td>IPF</td>\n",
       "      <td>IPF</td>\n",
       "      <td>World Men's Classic Championships</td>\n",
       "      <td>http://goodlift.info/onecompetition_dtl.php?li...</td>\n",
       "      <td>Powerlifting</td>\n",
       "      <td>Male - Raw Junior</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>Fujii Yuya</td>\n",
       "      <td>...</td>\n",
       "      <td>-265</td>\n",
       "      <td>160</td>\n",
       "      <td>-170</td>\n",
       "      <td>170</td>\n",
       "      <td>280</td>\n",
       "      <td>295</td>\n",
       "      <td>-300</td>\n",
       "      <td>715</td>\n",
       "      <td>105.22</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Meet Date Sanction Number Meet Location  \\\n",
       "0  09/23/2021 - 10/03/2021             IPF           IPF   \n",
       "\n",
       "                           Meet Name  \\\n",
       "0  World Men's Classic Championships   \n",
       "\n",
       "                                       Meet Director         Event  \\\n",
       "0  http://goodlift.info/onecompetition_dtl.php?li...  Powerlifting   \n",
       "\n",
       "            Category Weight Class Placement        Name  ... Squat 3  \\\n",
       "0  Male - Raw Junior           74         1  Fujii Yuya  ...    -265   \n",
       "\n",
       "  Bench Press 1 Bench Press 2 Bench Press 3 Deadlift 1 Deadlift 2 Deadlift 3  \\\n",
       "0           160          -170           170        280        295       -300   \n",
       "\n",
       "  Total  Points Drug-Tested  \n",
       "0   715  105.22              \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://usapl.liftingdatabase.com/competitions-view?id=120068'\n",
    "df = retrieve_info(url)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058d002e",
   "metadata": {},
   "source": [
    "**2. Create DataFrame of all competition names and types in USAPL Database.** \n",
    "\n",
    "This DataFrame contains information of where and when the competition occurred along with the url that stores the results of the competition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e2f42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame created from list of USAPL competitions.\n",
      "DataFrame saved as csv file in data folder.\n"
     ]
    }
   ],
   "source": [
    "list_of_urls = [\n",
    "    'https://usapl.liftingdatabase.com/competitions-default?t=5&s=',\n",
    "    'https://usapl.liftingdatabase.com/competitions-default?t=3&s=',\n",
    "    'https://usapl.liftingdatabase.com/competitions-default?t=7&s=',\n",
    "    'https://usapl.liftingdatabase.com/competitions-default?t=2&s=',\n",
    "    'https://usapl.liftingdatabase.com/competitions-default?t=9&s=',\n",
    "    'https://usapl.liftingdatabase.com/competitions-default?t=8&s=',\n",
    "    'https://usapl.liftingdatabase.com/competitions-default?t=4&s=',\n",
    "    'https://usapl.liftingdatabase.com/competitions-default?t=6&s='\n",
    "]\n",
    "\n",
    "competition_types = ['IPF', 'Local', 'NAPF', 'National', \n",
    "                     'Pro Meet', 'Pro Series', 'Regional', 'State']\n",
    "\n",
    "all_competitions = []\n",
    "\n",
    "# Go through list of URL and collect data\n",
    "for url, competition_type in zip(list_of_urls, competition_types):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # List to collect information from each competition \n",
    "        competition_info = []\n",
    "        \n",
    "        # Retrieve general information from list of competitions\n",
    "        tabledata = soup.find('table', 'tabledata')\n",
    "        if tabledata:\n",
    "            tr_tags = tabledata.findAll('tr')\n",
    "            \n",
    "            for tr_tag in tr_tags:\n",
    "                td_tags = tr_tag.findAll('td')\n",
    "\n",
    "                if td_tags:\n",
    "                    date = td_tags[0].get_text().strip()\n",
    "                    name = td_tags[1].get_text().strip()\n",
    "                    sanction_num = td_tags[2].get_text().strip()\n",
    "                    state = td_tags[3].get_text().strip()\n",
    "                    \n",
    "                    # Create a dictionary for each row\n",
    "                    meet_type_data = {\n",
    "                        'Date': date,\n",
    "                        'Name': name,\n",
    "                        'Meet Type': competition_type,\n",
    "                        'Sanction Number': sanction_num,\n",
    "                        'State': state\n",
    "                    }\n",
    "                    \n",
    "                    # Append dictionary to results list\n",
    "                    competition_info.append(meet_type_data)\n",
    "                    \n",
    "        else:\n",
    "            print(f'Error retrieving URL: {url}')\n",
    "            \n",
    "        # Retrieve URL information\n",
    "        anchor_tags = tabledata.findAll('a')\n",
    "        url_list = ['https://usapl.liftingdatabase.com/' + anchor_tag.get('href') for anchor_tag in anchor_tags]\n",
    "\n",
    "        # Update competition_info with Website info\n",
    "        for url, meet_type_data in enumerate(competition_info):\n",
    "            meet_type_data['Website'] = url_list[url]\n",
    "\n",
    "        # Append competition_info to overall list \n",
    "        all_competitions.extend(competition_info)\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "competition_type_df = pd.DataFrame(all_competitions)\n",
    "print('DataFrame created from list of USAPL competitions.')\n",
    "\n",
    "# Display and save DataFrame as csv\n",
    "competition_type_df\n",
    "\n",
    "competition_type_df.to_csv('../data/USAPL_competitions.csv', index = False)\n",
    "print('DataFrame saved as csv file in data folder.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830b4c6e",
   "metadata": {},
   "source": [
    "**3. Using list of url's from the previous code, retrieve results from each competition using retrieve_info function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b28fb3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Error retrieving https://usapl.liftingdatabase.com/https://docs.google.com/spreadsheets/d/1Al4TiaAWfMddLDETdiRyZIw3eElAlYTEvowd4ugzMcY/edit#gid=0\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Error retrieving data from https://usapl.liftingdatabase.com/competitions-view?id=2011: list index out of range\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Error retrieving https://usapl.liftingdatabase.com/https://docs.google.com/spreadsheets/d/1HnWXQGAxXTpjUVOP9FeEx92E6DcvbtIjXq0DwSqnO8I/edit?usp=sharing\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "DataFrame saved as csv file in data folder.\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "# Iterate through each complete URL\n",
    "for url in url_list:\n",
    "    df = retrieve_info(url)\n",
    "    dfs.append(df)\n",
    "    time.sleep(1)\n",
    "    \n",
    "# Concatenate all DataFrames into one\n",
    "USAPL_powerlifting_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "USAPL_powerlifting_df.to_csv('../data/usapl.csv', index = False)\n",
    "print('DataFrame saved as csv file in data folder.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d7419c",
   "metadata": {},
   "source": [
    "**4. Manually retrieve information from urls that did not work**\n",
    "\n",
    "Errors: \n",
    "- Cannot open google spreadsheets (2)\n",
    "    - https://usapl.liftingdatabase.com/https://docs.google.com/spreadsheets/d/1HnWXQGAxXTpjUVOP9FeEx92E6DcvbtIjXq0DwSqnO8I/edit?usp=sharing\n",
    "    - https://usapl.liftingdatabase.com/https://docs.google.com/spreadsheets/d/1Al4TiaAWfMddLDETdiRyZIw3eElAlYTEvowd4ugzMcY/edit#gid=0\n",
    "- 'NoneType' object has no attribute 'get_text' (5)\n",
    "    - https://usapl.liftingdatabase.com/competitions-view?id=1033:\n",
    "    - https://usapl.liftingdatabase.com/competitions-view?id=1038:\n",
    "    - https://usapl.liftingdatabase.com/competitions-view?id=1249:\n",
    "    - https://usapl.liftingdatabase.com/competitions-view?id=1632:\n",
    "    - https://usapl.liftingdatabase.com/competitions-view?id=1684:\n",
    "        - Resolved this issue by adding a None value to Event column in original retrieve_info function\n",
    "- list index out of range (1) \n",
    "    - https://usapl.liftingdatabase.com/competitions-view?id=2011:\n",
    "        - Used table[2] because table[1] is an 'Attachment' table\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102d214b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Meet Date</th>\n",
       "      <th>Meet Location</th>\n",
       "      <th>Meet Name</th>\n",
       "      <th>Meet Director</th>\n",
       "      <th>Event</th>\n",
       "      <th>Category</th>\n",
       "      <th>Weight Class</th>\n",
       "      <th>Placement</th>\n",
       "      <th>Name</th>\n",
       "      <th>Year of Birth</th>\n",
       "      <th>...</th>\n",
       "      <th>Squat 3</th>\n",
       "      <th>Bench Press 1</th>\n",
       "      <th>Bench Press 2</th>\n",
       "      <th>Bench Press 3</th>\n",
       "      <th>Deadlift 1</th>\n",
       "      <th>Deadlift 2</th>\n",
       "      <th>Deadlift 3</th>\n",
       "      <th>Total</th>\n",
       "      <th>Points</th>\n",
       "      <th>Drug-Tested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04/07/2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pennsylvania States</td>\n",
       "      <td>Steve Mann</td>\n",
       "      <td>Bench press</td>\n",
       "      <td>Female - Raw Master 1</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>Karen Backenstose</td>\n",
       "      <td>1976</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>60</td>\n",
       "      <td>65</td>\n",
       "      <td>-70</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>65</td>\n",
       "      <td>76.69</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04/07/2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pennsylvania States</td>\n",
       "      <td>Steve Mann</td>\n",
       "      <td>Bench press</td>\n",
       "      <td>Male - Raw Master 2</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>Joseph Zwick</td>\n",
       "      <td>1957</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>105</td>\n",
       "      <td>110</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>110</td>\n",
       "      <td>66.48</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/07/2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pennsylvania States</td>\n",
       "      <td>Steve Mann</td>\n",
       "      <td>Bench press</td>\n",
       "      <td>Male - Raw Master 3</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>Thomas Wilde</td>\n",
       "      <td>1948</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>82.5</td>\n",
       "      <td>85</td>\n",
       "      <td>-90</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>85</td>\n",
       "      <td>61.38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/07/2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pennsylvania States</td>\n",
       "      <td>Steve Mann</td>\n",
       "      <td>Bench press</td>\n",
       "      <td>Male - Raw Master 3</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>Sam Romeo</td>\n",
       "      <td>1955</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>82.5</td>\n",
       "      <td>85</td>\n",
       "      <td>87.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>87.5</td>\n",
       "      <td>62.82</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04/07/2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pennsylvania States</td>\n",
       "      <td>Steve Mann</td>\n",
       "      <td>Bench press</td>\n",
       "      <td>Male - Raw Master 3</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>Jim Mckenna</td>\n",
       "      <td>1948</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>130</td>\n",
       "      <td>142.5</td>\n",
       "      <td>-147.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>142.5</td>\n",
       "      <td>87.52</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>04/07/2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pennsylvania States</td>\n",
       "      <td>Steve Mann</td>\n",
       "      <td>Powerlifting</td>\n",
       "      <td>Male - Raw Teen 3</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>John Gamber</td>\n",
       "      <td>1998</td>\n",
       "      <td>...</td>\n",
       "      <td>195</td>\n",
       "      <td>137.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>-145</td>\n",
       "      <td>215</td>\n",
       "      <td>-225</td>\n",
       "      <td></td>\n",
       "      <td>552.5</td>\n",
       "      <td>356.03</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>04/07/2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pennsylvania States</td>\n",
       "      <td>Steve Mann</td>\n",
       "      <td>Powerlifting</td>\n",
       "      <td>Male - Raw Teen 3</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>Charlie Hechter</td>\n",
       "      <td>1999</td>\n",
       "      <td>...</td>\n",
       "      <td>245</td>\n",
       "      <td>127.5</td>\n",
       "      <td>137.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>250</td>\n",
       "      <td>265</td>\n",
       "      <td>277.5</td>\n",
       "      <td>665</td>\n",
       "      <td>403.59</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>04/07/2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pennsylvania States</td>\n",
       "      <td>Steve Mann</td>\n",
       "      <td>Powerlifting</td>\n",
       "      <td>Male - Raw Youth</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Rowan Kratz</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>62.5</td>\n",
       "      <td>27.5</td>\n",
       "      <td>32.5</td>\n",
       "      <td>-36.5</td>\n",
       "      <td>75</td>\n",
       "      <td>85</td>\n",
       "      <td>93</td>\n",
       "      <td>188</td>\n",
       "      <td>251.06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>04/07/2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pennsylvania States</td>\n",
       "      <td>Steve Mann</td>\n",
       "      <td>Powerlifting</td>\n",
       "      <td>Male - Raw Youth</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>Evan McCracken</td>\n",
       "      <td>2005</td>\n",
       "      <td>...</td>\n",
       "      <td>85</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>92.5</td>\n",
       "      <td>100</td>\n",
       "      <td>105</td>\n",
       "      <td>240</td>\n",
       "      <td>237.91</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>04/07/2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pennsylvania States</td>\n",
       "      <td>Steve Mann</td>\n",
       "      <td>Powerlifting</td>\n",
       "      <td>Male - Teen 2</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>Ricky Kryeski</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>182.5</td>\n",
       "      <td>135</td>\n",
       "      <td>145</td>\n",
       "      <td>150</td>\n",
       "      <td>205</td>\n",
       "      <td>220</td>\n",
       "      <td>-227.5</td>\n",
       "      <td>552.5</td>\n",
       "      <td>343.99</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Meet Date Meet Location            Meet Name Meet Director  \\\n",
       "0    04/07/2018  Pennsylvania  Pennsylvania States    Steve Mann   \n",
       "1    04/07/2018  Pennsylvania  Pennsylvania States    Steve Mann   \n",
       "2    04/07/2018  Pennsylvania  Pennsylvania States    Steve Mann   \n",
       "3    04/07/2018  Pennsylvania  Pennsylvania States    Steve Mann   \n",
       "4    04/07/2018  Pennsylvania  Pennsylvania States    Steve Mann   \n",
       "..          ...           ...                  ...           ...   \n",
       "135  04/07/2018  Pennsylvania  Pennsylvania States    Steve Mann   \n",
       "136  04/07/2018  Pennsylvania  Pennsylvania States    Steve Mann   \n",
       "137  04/07/2018  Pennsylvania  Pennsylvania States    Steve Mann   \n",
       "138  04/07/2018  Pennsylvania  Pennsylvania States    Steve Mann   \n",
       "139  04/07/2018  Pennsylvania  Pennsylvania States    Steve Mann   \n",
       "\n",
       "            Event               Category Weight Class Placement  \\\n",
       "0     Bench press  Female - Raw Master 1           57         1   \n",
       "1     Bench press    Male - Raw Master 2          105         1   \n",
       "2     Bench press    Male - Raw Master 3           74         1   \n",
       "3     Bench press    Male - Raw Master 3           83         1   \n",
       "4     Bench press    Male - Raw Master 3          105         1   \n",
       "..            ...                    ...          ...       ...   \n",
       "135  Powerlifting      Male - Raw Teen 3           93         2   \n",
       "136  Powerlifting      Male - Raw Teen 3          105         1   \n",
       "137  Powerlifting       Male - Raw Youth           40         1   \n",
       "138  Powerlifting       Male - Raw Youth           53         1   \n",
       "139  Powerlifting          Male - Teen 2          105         1   \n",
       "\n",
       "                  Name Year of Birth  ... Squat 3 Bench Press 1 Bench Press 2  \\\n",
       "0    Karen Backenstose          1976  ...                    60            65   \n",
       "1         Joseph Zwick          1957  ...                   100           105   \n",
       "2         Thomas Wilde          1948  ...                  82.5            85   \n",
       "3            Sam Romeo          1955  ...                  82.5            85   \n",
       "4          Jim Mckenna          1948  ...                   130         142.5   \n",
       "..                 ...           ...  ...     ...           ...           ...   \n",
       "135        John Gamber          1998  ...     195         137.5         142.5   \n",
       "136    Charlie Hechter          1999  ...     245         127.5         137.5   \n",
       "137        Rowan Kratz          2006  ...    62.5          27.5          32.5   \n",
       "138     Evan McCracken          2005  ...      85            40            45   \n",
       "139      Ricky Kryeski          2000  ...   182.5           135           145   \n",
       "\n",
       "    Bench Press 3 Deadlift 1 Deadlift 2 Deadlift 3  Total  Points Drug-Tested  \n",
       "0             -70                                      65   76.69              \n",
       "1             110                                     110   66.48              \n",
       "2             -90                                      85   61.38              \n",
       "3            87.5                                    87.5   62.82              \n",
       "4          -147.5                                   142.5   87.52              \n",
       "..            ...        ...        ...        ...    ...     ...         ...  \n",
       "135          -145        215       -225             552.5  356.03              \n",
       "136         142.5        250        265      277.5    665  403.59           X  \n",
       "137         -36.5         75         85         93    188  251.06              \n",
       "138            50       92.5        100        105    240  237.91              \n",
       "139           150        205        220     -227.5  552.5  343.99              \n",
       "\n",
       "[140 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_category(td_tag):\n",
    "    th_tag_before = td_tag.find_previous('th')  # Find the previous th tag\n",
    "    th_tag_after = td_tag.find_next('th')  # Find the next th tag\n",
    "\n",
    "    if th_tag_before and th_tag_after:\n",
    "        # If the td tag is between two th tags, retrieve the previous th element\n",
    "        return th_tag_before.get_text().strip()\n",
    "    elif th_tag_before:\n",
    "        # If the td tag is after a th tag, retrieve the previous th element\n",
    "        return th_tag_before.get_text().strip()\n",
    "    elif th_tag_after:\n",
    "        # If the td tag is before a th tag, retrieve the next th element\n",
    "        return th_tag_after.get_text().strip()\n",
    "    else:\n",
    "        return None    \n",
    "url = 'https://usapl.liftingdatabase.com/competitions-view?id=2011'\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text)    \n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Main html element where data is located \n",
    "    content = soup.find('div', id=\"content\")\n",
    "\n",
    "    if content:\n",
    "        tables = content.findAll('table')\n",
    "\n",
    "        if tables: \n",
    "            meet_info = tables[0]\n",
    "            meet_results = tables[2]\n",
    "\n",
    "            # This is the table with competitor results\n",
    "            if meet_results:\n",
    "                tr_tags = meet_results.findAll('tr')\n",
    "\n",
    "                for tr_tag in tr_tags:\n",
    "                    td_tags = tr_tag.findAll('td')\n",
    "\n",
    "                    if len(td_tags) >= 2:\n",
    "                        category = extract_category(td_tags[0])\n",
    "                        weight_class = td_tags[0].get_text().strip().replace('-', '')\n",
    "                        placement = td_tags[1].get_text().strip().replace('.', '')\n",
    "                        name = td_tags[2].get_text().strip()\n",
    "                        yob = td_tags[3].get_text().strip()\n",
    "                        team = td_tags[4].get_text().strip()\n",
    "                        state = td_tags[5].get_text().strip()\n",
    "                        lot = td_tags[6].get_text().strip()\n",
    "                        weight = td_tags[7].get_text().strip()\n",
    "                        squat_1 = td_tags[8].get_text().strip()\n",
    "                        squat_2 = td_tags[9].get_text().strip()\n",
    "                        squat_3 = td_tags[10].get_text().strip()\n",
    "                        bench_1 = td_tags[11].get_text().strip()\n",
    "                        bench_2 = td_tags[12].get_text().strip()\n",
    "                        bench_3 = td_tags[13].get_text().strip()\n",
    "                        deadlift_1 = td_tags[14].get_text().strip()\n",
    "                        deadlift_2 = td_tags[15].get_text().strip()\n",
    "                        deadlift_3 = td_tags[16].get_text().strip()\n",
    "                        total = td_tags[17].get_text().strip()\n",
    "                        points = td_tags[18].get_text().strip()\n",
    "                        drug_tested = td_tags[19].get_text().strip()\n",
    "\n",
    "                        # Find the previous th tag for the event\n",
    "                        event_tag = tr_tag.find_previous('th', 'competition_view_event')\n",
    "                        \n",
    "                        if event_tag: \n",
    "                            event = event_tag.get_text().strip()\n",
    "                            \n",
    "                        else: \n",
    "                            event = None\n",
    "                        \n",
    "                        # Create a dictionary for each row\n",
    "                        meet_results_data = {\n",
    "                            'Event': event,\n",
    "                            'Category': category,\n",
    "                            'Weight Class': weight_class,\n",
    "                            'Placement': placement,\n",
    "                            'Name': name,\n",
    "                            'Year of Birth': yob,\n",
    "                            'Team': team,\n",
    "                            'State': state,\n",
    "                            'Lot': lot,\n",
    "                            'Weight': weight,\n",
    "                            'Squat 1': squat_1,\n",
    "                            'Squat 2': squat_2,\n",
    "                            'Squat 3': squat_3,\n",
    "                            'Bench Press 1': bench_1,\n",
    "                            'Bench Press 2': bench_2,\n",
    "                            'Bench Press 3': bench_3,\n",
    "                            'Deadlift 1': deadlift_1,\n",
    "                            'Deadlift 2': deadlift_2,\n",
    "                            'Deadlift 3': deadlift_3,\n",
    "                            'Total': total,\n",
    "                            'Points': points,\n",
    "                            'Drug-Tested': drug_tested\n",
    "                        }\n",
    "\n",
    "                        # Append the dictionary to the results list\n",
    "                        results.append(meet_results_data)\n",
    "                \n",
    "                # Create a DataFrame from the results list\n",
    "                meet_results_df = pd.DataFrame(results)\n",
    "\n",
    "            # This is table with meet information\n",
    "            if meet_info:\n",
    "                tr_tags = meet_info.findAll('tr')\n",
    "\n",
    "                # Extracting date, state, and meet director information from tr_tags list\n",
    "                if len(tr_tags) >= 4:\n",
    "                    date = tr_tags[0].find('td').get_text(strip=True)\n",
    "                    sanction_num = tr_tags[1].find('td').get_text(strip=True)\n",
    "                    state = tr_tags[2].find('td').get_text(strip=True)\n",
    "                    meet_director = tr_tags[3].find('td').get_text(strip=True)\n",
    "\n",
    "                else: \n",
    "                    date = sanction_num = state = meet_director = None\n",
    "\n",
    "                # Repeat the values for each row in meet_results_df \n",
    "                meet_info_df = pd.DataFrame({\n",
    "                    'Meet Date': [date] * len(results),\n",
    "                    'Sanction Number': [sanction_num] * len(results),\n",
    "                    'Meet Location': [state] * len(results),\n",
    "                    'Meet Director': [meet_director] * len(results)                \n",
    "                })\n",
    "\n",
    "                # Concatenate the dataframes along the columns \n",
    "                results_df = pd.concat([meet_info_df, meet_results_df], axis=1)\n",
    "\n",
    "            # Retrieve meet name from h3 heading\n",
    "            # Create a new column to add to results_df\n",
    "            meet_name = content.find('h3').get_text(strip=True)\n",
    "            meet_name_df = pd.DataFrame({\n",
    "                'Meet Name': [meet_name] * len(results)\n",
    "            })\n",
    "\n",
    "            # Concatenate the dataframes along the columns \n",
    "            results_df = pd.concat([results_df, meet_name_df], axis = 1)                        \n",
    "\n",
    "            #Reorder columns in the DataFrame \n",
    "            column_order = [\n",
    "                'Meet Date', 'Meet Location', 'Meet Name', 'Meet Director', \n",
    "                'Event', 'Category', 'Weight Class', 'Placement', 'Name', \n",
    "                'Year of Birth', 'Team', 'State', 'Lot', 'Weight', \n",
    "                'Squat 1', 'Squat 2', 'Squat 3', 'Bench Press 1', \n",
    "                'Bench Press 2', 'Bench Press 3', 'Deadlift 1', \n",
    "                'Deadlift 2', 'Deadlift 3', 'Total', 'Points', 'Drug-Tested'\n",
    "            ]\n",
    "            PennState2018_df = results_df[column_order]\n",
    "\n",
    "            print('Success!')\n",
    "                \n",
    "display(PennState2018_df)                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af2ce3a",
   "metadata": {},
   "source": [
    "**5. Combine USAPL_powerlifting_df and PennState2018_df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66573326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as csv file in data folder.\n"
     ]
    }
   ],
   "source": [
    "USAPL_powerlifting_df = pd.concat([USAPL_powerlifting_df, PennState2018_df], axis = 0)\n",
    "\n",
    "USAPL_powerlifting_df.to_csv('../data/usapl.csv', index = False)\n",
    "print('DataFrame saved as csv file in data folder.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8eef07",
   "metadata": {},
   "source": [
    "**There's a major difference in number of competitions in each DataFrame (usapl = 390 vs copm_types = 3255). Find out how to retrieve the other missing data.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
